{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(('liwc', 'nrc', 'mpqa_arg')) == ['liwc', 'nrc', 'mpqa_arg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elba_ro\\Documents\\projects\\nlpcss2020-editorials-analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\elba_ro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\elba_ro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from langdetect import detect\n",
    "import langdetect\n",
    "import numpy as np\n",
    "import importlib\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "%cd ..\n",
    "import textmining.text_miner \n",
    "import textmining.loader  as loader\n",
    "import textmining.topic_modeler as tm\n",
    "import textmining.significance_testing as significance_testing\n",
    "import textmining.utility as utility\n",
    "import textmining.analysis as analysis\n",
    "import textmining.cluster_analysis as cluster_analysis\n",
    "import textmining.machine_learning as machine_learning\n",
    "import textmining.news_editorials_experiments as experiment\n",
    "import textmining.cross_models_significance as cross\n",
    "\n",
    "importlib.reload(textmining.machine_learning)\n",
    "importlib.reload(textmining.news_editorials_experiments)\n",
    "importlib.reload(textmining.cross_models_significance)\n",
    "importlib.reload(textmining.cluster_analysis)\n",
    "importlib.reload(textmining.text_miner)\n",
    "\n",
    "importlib.reload(textmining.text_miner)\n",
    "importlib.reload(textmining.topic_modeler)\n",
    "importlib.reload(textmining.analysis)\n",
    "importlib.reload(textmining.loader)\n",
    "os.chdir(current_dir)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trait = 'openness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"corpus\" is set. It contains the 6000 annotation\n"
     ]
    }
   ],
   "source": [
    "load = loader.loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_df = load.load_personality_traits()\n",
    "personality_df.set_index('id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HIGH       9\n",
       "AVERAGE    8\n",
       "LOW        7\n",
       "Name: openness, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traints\n",
    "#def set_avg_to_low(row):\n",
    "#    row[trait] = 'LOW' if row[trait] == 'AVERAGE' else row[trait]\n",
    "#    return row\n",
    "#personality_df = personality_df.apply(set_avg_to_low, axis=1)\n",
    "personality_df[[trait]]\n",
    "personality_df[trait].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"corpus\" is set with personality: \"a\" , \"b\", ...\n"
     ]
    }
   ],
   "source": [
    "corpus = load.corpus\n",
    "corpus = load.add_personality_label(personality_df[[trait]], trait)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HIGH       2250\n",
       "AVERAGE    2000\n",
       "LOW        1750\n",
       "Name: openness, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[trait].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(effect_abstracted    1    2     3\n",
       " openness                         \n",
       " AVERAGE            262  565  1173\n",
       " HIGH               250  530  1470\n",
       " LOW                175  895   680,\n",
       " None,\n",
       " None,\n",
       " effect     1    2    3    4    5\n",
       " openness                        \n",
       " AVERAGE   60  202  565  626  547\n",
       " HIGH      62  188  530  968  502\n",
       " LOW       21  154  895  606   74)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(corpus[trait], corpus.effect_abstracted), print(''),print(''), pd.crosstab(corpus[trait], corpus.effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'high_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c9f68ba73b00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhigh_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhigh_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'multi_majority'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlow_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlow_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'multi_majority'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'high_df' is not defined"
     ]
    }
   ],
   "source": [
    "high_df[high_df['multi_majority'] == True]\n",
    "low_df[low_df['multi_majority'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles dataframe for ideology AVERAGE was created\n",
      "The id of the df is the article id without txt\n",
      "total con: 979\n",
      "rounded TRAINGING data:  783\n",
      "rounded Validation data:  0\n",
      "rounded Test data:  196\n",
      "total con: 1000\n",
      "rounded TRAINGING data:  800\n",
      "rounded Validation data:  0\n",
      "rounded Test data:  200\n",
      "\"data_division\" is set as dict with keys  dict_keys(['train', 'test'])\n",
      "\"corpus\" is set with split_label: \"train\" \"test\"\n",
      "\"data_division\" is set as dict with keys  dict_keys(['train', 'test'])\n",
      "length of self.df:  979\n",
      "length of self.data_division_df:  979\n",
      "length of self.df:  979\n",
      "articles dataframe for ideology HIGH was created\n",
      "The id of the df is the article id without txt\n",
      "total con: 979\n",
      "rounded TRAINGING data:  783\n",
      "rounded Validation data:  0\n",
      "rounded Test data:  196\n",
      "total con: 1000\n",
      "rounded TRAINGING data:  800\n",
      "rounded Validation data:  0\n",
      "rounded Test data:  200\n",
      "\"data_division\" is set as dict with keys  dict_keys(['train', 'test'])\n",
      "\"corpus\" is set with split_label: \"train\" \"test\"\n",
      "\"data_division\" is set as dict with keys  dict_keys(['train', 'test'])\n",
      "length of self.df:  979\n",
      "length of self.data_division_df:  979\n",
      "length of self.df:  979\n",
      "articles dataframe for ideology LOW was created\n",
      "The id of the df is the article id without txt\n",
      "total con: 979\n",
      "rounded TRAINGING data:  783\n",
      "rounded Validation data:  0\n",
      "rounded Test data:  196\n",
      "total con: 1000\n",
      "rounded TRAINGING data:  800\n",
      "rounded Validation data:  0\n",
      "rounded Test data:  200\n",
      "\"data_division\" is set as dict with keys  dict_keys(['train', 'test'])\n",
      "\"corpus\" is set with split_label: \"train\" \"test\"\n",
      "\"data_division\" is set as dict with keys  dict_keys(['train', 'test'])\n",
      "length of self.df:  979\n",
      "length of self.data_division_df:  979\n",
      "length of self.df:  979\n"
     ]
    }
   ],
   "source": [
    "consc_maj_df = load.get_article_dfs_per_ideology(ideology = trait, include_content = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_df = consc_maj_df['HIGH']\n",
    "average_df = consc_maj_df['AVERAGE']\n",
    "low_df = consc_maj_df['LOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_all_0(df):\n",
    "    df\n",
    "    return  df[(df['challenging']== 1) & (df['no_effect']== 0) & (df['reinforcing']== 0)]\n",
    "\n",
    "high_df['sum_']= high_df['challenging'] + high_df['no_effect'] +high_df['reinforcing']\n",
    "\n",
    "low_df['sum_']= low_df['challenging'] + low_df['no_effect'] +low_df['reinforcing']\n",
    "high_df['sum_'].value_counts(), low_df['sum_'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_effect      409\n",
      "reinforcing    408\n",
      "challenging    162\n",
      "Name: majority, dtype: int64\n",
      "\n",
      "reinforcing    561\n",
      "no_effect      262\n",
      "challenging    156\n",
      "Name: majority, dtype: int64\n",
      "\n",
      "reinforcing    662\n",
      "challenging    183\n",
      "no_effect      134\n",
      "Name: majority, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(low_df.majority.value_counts())\n",
    "\n",
    "print()\n",
    "\n",
    "print(average_df.majority.value_counts())\n",
    "print()\n",
    "\n",
    "print(high_df.majority.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train    783\n",
      "test     196\n",
      "Name: split_label, dtype: int64\n",
      "\n",
      "train    783\n",
      "test     196\n",
      "Name: split_label, dtype: int64\n",
      "\n",
      "train    783\n",
      "test     196\n",
      "Name: split_label, dtype: int64\n",
      "\n",
      "\n",
      "split_label  test  train\n",
      "majority                \n",
      "challenging    29    133\n",
      "no_effect      93    316\n",
      "reinforcing    74    334\n",
      "\n",
      "split_label  test  train\n",
      "majority                \n",
      "challenging    31    125\n",
      "no_effect      42    220\n",
      "reinforcing   123    438\n",
      "\n",
      "split_label  test  train\n",
      "majority                \n",
      "challenging    35    148\n",
      "no_effect      28    106\n",
      "reinforcing   133    529\n"
     ]
    }
   ],
   "source": [
    "print(low_df.split_label.value_counts())\n",
    "print()\n",
    "print(average_df.split_label.value_counts())\n",
    "print()\n",
    "print(high_df.split_label.value_counts())\n",
    "print()\n",
    "print()\n",
    "print(pd.crosstab(low_df.majority, low_df.split_label))\n",
    "print()\n",
    "print(pd.crosstab(average_df.majority, average_df.split_label))\n",
    "print()\n",
    "print(pd.crosstab(high_df.majority, high_df.split_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_df.rename(columns = {'majority': trait+'_high_majority'}, inplace = True)\n",
    "average_df.rename(columns = {'majority': trait+'_average_majority'}, inplace = True)\n",
    "low_df.rename(columns = {'majority': trait+'_low_majority'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../data/articles_with_adu_liwc_lexicons_content.json', orient='records')\n",
    "data.set_index('idx', inplace=True)\n",
    "print(len(data))\n",
    "data = data.merge(high_df[[trait+'_high_majority']], how=\"inner\",left_index=True, right_index=True )\n",
    "data = data.merge(average_df[[trait+'_average_majority']], how=\"inner\",left_index=True, right_index=True )\n",
    "data = data.merge(low_df[[trait+'_low_majority']], how=\"inner\",left_index=True, right_index=True )\n",
    "\n",
    "data.drop(['liberal_majority', 'conservative_majority'], axis=1, inplace=True)\n",
    "data.to_csv('../data/'+trait+'_HAL_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, test_df = analysis.get_train_test(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/'+trait+'_HAL_all_features.csv', index_col='idx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running experiments for ideologies:  ['openness_average_majority'] \n",
      " remove_outliers:  True \n",
      " normalize:  sqrt\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "('liwc',)\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.3 time(s):  8.683\n",
      "-------------------------------------------\n",
      "('nrc',)\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.35 time(s):  1.798\n",
      "-------------------------------------------\n",
      "('mpqa_arg',)\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.22 time(s):  1.127\n",
      "-------------------------------------------\n",
      "('mpqa_subjobg',)\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.24 time(s):  0.432\n",
      "-------------------------------------------\n",
      "('adu',)\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.31 time(s):  0.269\n",
      "-------------------------------------------\n",
      "('lemma',)\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.4 time(s):  2.883\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.35 time(s):  6.999\n",
      "-------------------------------------------\n",
      "('liwc', 'mpqa_arg')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.3 time(s):  10.808\n",
      "-------------------------------------------\n",
      "('liwc', 'mpqa_subjobg')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.28 time(s):  6.769\n",
      "-------------------------------------------\n",
      "('liwc', 'adu')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.31 time(s):  6.874\n",
      "-------------------------------------------\n",
      "('liwc', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.35 time(s):  8.389\n",
      "-------------------------------------------\n",
      "('nrc', 'mpqa_arg')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.34 time(s):  3.86\n",
      "-------------------------------------------\n",
      "('nrc', 'mpqa_subjobg')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.33 time(s):  1.913\n",
      "-------------------------------------------\n",
      "('nrc', 'adu')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.35 time(s):  1.911\n",
      "-------------------------------------------\n",
      "('nrc', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.4 time(s):  5.88\n",
      "-------------------------------------------\n",
      "('mpqa_arg', 'mpqa_subjobg')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.21 time(s):  1.22\n",
      "-------------------------------------------\n",
      "('mpqa_arg', 'adu')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.27 time(s):  0.818\n",
      "-------------------------------------------\n",
      "('mpqa_arg', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.36 time(s):  3.469\n",
      "-------------------------------------------\n",
      "('mpqa_subjobg', 'adu')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.3 time(s):  0.43\n",
      "-------------------------------------------\n",
      "('mpqa_subjobg', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.37 time(s):  3.435\n",
      "-------------------------------------------\n",
      "('adu', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.39 time(s):  3.216\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'mpqa_arg')\n",
      "training and testing\n",
      "macro-f1:  0.31 time(s):  0.239\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'mpqa_subjobg')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.34 time(s):  6.542\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'adu')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.35 time(s):  7.65\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.38 time(s):  11.469\n",
      "-------------------------------------------\n",
      "('liwc', 'mpqa_arg', 'mpqa_subjobg')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.23 time(s):  5.883\n",
      "-------------------------------------------\n",
      "('liwc', 'mpqa_arg', 'adu')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.28 time(s):  11.808\n",
      "-------------------------------------------\n",
      "('liwc', 'mpqa_arg', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.36 time(s):  8.497\n",
      "-------------------------------------------\n",
      "('liwc', 'mpqa_subjobg', 'adu')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.33 time(s):  4.858\n",
      "-------------------------------------------\n",
      "('liwc', 'mpqa_subjobg', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.39 time(s):  8.656\n",
      "-------------------------------------------\n",
      "('liwc', 'adu', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.4 time(s):  8.766\n",
      "-------------------------------------------\n",
      "('nrc', 'mpqa_arg', 'mpqa_subjobg')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.34 time(s):  8.701\n",
      "-------------------------------------------\n",
      "('nrc', 'mpqa_arg', 'adu')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.32 time(s):  10.737\n",
      "-------------------------------------------\n",
      "('nrc', 'mpqa_arg', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.35 time(s):  7.245\n",
      "-------------------------------------------\n",
      "('nrc', 'mpqa_subjobg', 'adu')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.37 time(s):  3.123\n",
      "-------------------------------------------\n",
      "('nrc', 'mpqa_subjobg', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.37 time(s):  7.295\n",
      "-------------------------------------------\n",
      "('nrc', 'adu', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.35 time(s):  7.278\n",
      "-------------------------------------------\n",
      "('mpqa_arg', 'mpqa_subjobg', 'adu')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.24 time(s):  1.092\n",
      "-------------------------------------------\n",
      "('mpqa_arg', 'mpqa_subjobg', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.35 time(s):  4.649\n",
      "-------------------------------------------\n",
      "('mpqa_arg', 'adu', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.4 time(s):  3.973\n",
      "-------------------------------------------\n",
      "('mpqa_subjobg', 'adu', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.38 time(s):  4.034\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'mpqa_arg', 'mpqa_subjobg')\n",
      "training and testing\n",
      "macro-f1:  0.29 time(s):  0.277\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'mpqa_arg', 'adu')\n",
      "training and testing\n",
      "macro-f1:  0.3 time(s):  0.338\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'mpqa_arg', 'lemma')\n",
      "training and testing\n",
      "macro-f1:  0.36 time(s):  0.754\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.37 time(s):  9.581\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.39 time(s):  11.905\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'adu', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.33 time(s):  12.873\n",
      "-------------------------------------------\n",
      "('liwc', 'mpqa_arg', 'mpqa_subjobg', 'adu')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.27 time(s):  13.693\n",
      "-------------------------------------------\n",
      "('liwc', 'mpqa_arg', 'mpqa_subjobg', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.36 time(s):  10.591\n",
      "-------------------------------------------\n",
      "('liwc', 'mpqa_arg', 'adu', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.35 time(s):  9.001\n",
      "-------------------------------------------\n",
      "('liwc', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.38 time(s):  9.812\n",
      "-------------------------------------------\n",
      "('nrc', 'mpqa_arg', 'mpqa_subjobg', 'adu')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.33 time(s):  4.696\n",
      "-------------------------------------------\n",
      "('nrc', 'mpqa_arg', 'mpqa_subjobg', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.35 time(s):  7.478\n",
      "-------------------------------------------\n",
      "('nrc', 'mpqa_arg', 'adu', 'lemma')\n",
      "performing gridsearch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and testing\n",
      "macro-f1:  0.35 time(s):  6.634\n",
      "-------------------------------------------\n",
      "('nrc', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.35 time(s):  6.802\n",
      "-------------------------------------------\n",
      "('mpqa_arg', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.39 time(s):  4.435\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'mpqa_arg', 'mpqa_subjobg', 'adu')\n",
      "training and testing\n",
      "macro-f1:  0.29 time(s):  0.305\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'mpqa_arg', 'mpqa_subjobg', 'lemma')\n",
      "training and testing\n",
      "macro-f1:  0.37 time(s):  0.738\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'mpqa_arg', 'adu', 'lemma')\n",
      "training and testing\n",
      "macro-f1:  0.34 time(s):  0.722\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.36 time(s):  12.177\n",
      "-------------------------------------------\n",
      "('liwc', 'mpqa_arg', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.33 time(s):  8.942\n",
      "-------------------------------------------\n",
      "('nrc', 'mpqa_arg', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "performing gridsearch\n",
      "training and testing\n",
      "macro-f1:  0.35 time(s):  7.928\n",
      "-------------------------------------------\n",
      "('liwc', 'nrc', 'mpqa_arg', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "training and testing\n",
      "macro-f1:  0.34 time(s):  0.732\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_sqrt = experiment.run_experiments(df, ideologies=[#trait+'_high_majority', \n",
    "                                                             trait+'_average_majority'],\n",
    "                                                            # trait+'_low_majority',],\n",
    "                                              filename=\"../out/style_content_models_results/\"+trait+\"_HAL_experiments_sqrt\",\n",
    "                                              remove_outliers=True,\n",
    "                                              normalize=\"sqrt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using standard scaler...\n",
      "Normalizing by using standard scaler...\n",
      "normalized\n",
      "end of get_x_y.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'macro': 0.26,\n",
       " 'micro': 0.28,\n",
       " 'challenging': 0.25,\n",
       " 'no_effect': 0.22,\n",
       " 'reinforcing': 0.32}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.train_baseline(df, trait+'_high_majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using standard scaler...\n",
      "Normalizing by using standard scaler...\n",
      "normalized\n",
      "end of get_x_y.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'macro': 0.29,\n",
       " 'micro': 0.3,\n",
       " 'challenging': 0.18,\n",
       " 'no_effect': 0.34,\n",
       " 'reinforcing': 0.34}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.train_baseline(df, trait+'_average_majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using standard scaler...\n",
      "Normalizing by using standard scaler...\n",
      "normalized\n",
      "end of get_x_y.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'macro': 0.33,\n",
       " 'micro': 0.35,\n",
       " 'challenging': 0.24,\n",
       " 'no_effect': 0.46,\n",
       " 'reinforcing': 0.29}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.train_baseline(df, trait+'_low_majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in ['low', 'high']:\n",
    "    print(l)\n",
    "    #print(results_minmax[ '{}_{}_majority'.format(trait, l)].macro.max() )\n",
    "    #print(results_log[ '{}_{}_majority'.format(trait, l)].macro.max() )\n",
    "    print(results_sqrt[ '{}_{}_majority'.format(trait, l)].macro.max() )\n",
    "    #print(results_standard[ '{}_{}_majority'.format(trait, l)].macro.max() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('lemma',)) 2\n",
      "('dummy',)\n",
      "('lemma',)\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('liwc', 'nrc', 'adu')) 2\n",
      "('dummy',)\n",
      "('liwc', 'nrc', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('liwc', 'nrc', 'adu', 'lemma')) 2\n",
      "('dummy',)\n",
      "('liwc', 'nrc', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('liwc', 'nrc', 'mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('dummy',)\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('nrc', 'mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('dummy',)\n",
      "('nrc', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('liwc', 'nrc', 'adu')) 2\n",
      "('lemma',)\n",
      "('liwc', 'nrc', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('liwc', 'nrc', 'adu', 'lemma')) 2\n",
      "('lemma',)\n",
      "('liwc', 'nrc', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('liwc', 'nrc', 'mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('lemma',)\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('nrc', 'mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('lemma',)\n",
      "('nrc', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'nrc', 'adu'), ('liwc', 'nrc', 'adu', 'lemma')) 2\n",
      "('liwc', 'nrc', 'adu')\n",
      "('liwc', 'nrc', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'nrc', 'adu'), ('liwc', 'nrc', 'mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('liwc', 'nrc', 'adu')\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'nrc', 'adu'), ('nrc', 'mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('liwc', 'nrc', 'adu')\n",
      "('nrc', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'nrc', 'adu', 'lemma'), ('liwc', 'nrc', 'mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('liwc', 'nrc', 'adu', 'lemma')\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'nrc', 'adu', 'lemma'), ('nrc', 'mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('liwc', 'nrc', 'adu', 'lemma')\n",
      "('nrc', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'nrc', 'mpqa_subjobg', 'adu', 'lemma'), ('nrc', 'mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu', 'lemma')\n",
      "('nrc', 'mpqa_subjobg', 'adu', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "level= 'high'\n",
    "PATH_RESULT= '../out/style_content_models_results/{}_HAL_experiments_{}_{}_{}_majority.csv'\n",
    "\n",
    "high_cross_models_sqrt_df    = cross.run_model_pairs_significance(PATH_RESULT.format(trait,'sqrt',trait, level), \n",
    "                                                                  df, '{}_{}_majority'.format(trait, level), \n",
    "                                                                  'sqrt'    , 'sqrt_{}_{}'.format(trait, level) \n",
    "                                                                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#high_cross_models_log_df     = cross.run_model_pairs_significance(PATH_RESULT.format('log', level), df, '{}_{}_majority'.format(trait, level), 'log'     , 'log_{}_{}'.format(trait, level) )\n",
    "#high_cross_models_minmax_df  = cross.run_model_pairs_significance(PATH_RESULT.format('minmax', level), df, '{}_{}_majority'.format(trait, level), 'minmax'   , 'minmax_{}_{}'.format(trait, level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_pair</th>\n",
       "      <th>is_normal</th>\n",
       "      <th>stat</th>\n",
       "      <th>p_val</th>\n",
       "      <th>wilk_stat</th>\n",
       "      <th>wilk_p_val</th>\n",
       "      <th>significant</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>((lemma,), (liwc, nrc, adu, lemma))</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.216641</td>\n",
       "      <td>0.090951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043114</td>\n",
       "      <td>True</td>\n",
       "      <td>{'('lemma',)': [0.4695974134334584, 0.35405583...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>((lemma,), (nrc, mpqa_subjobg, adu, lemma))</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.843135</td>\n",
       "      <td>0.046719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043114</td>\n",
       "      <td>True</td>\n",
       "      <td>{'('lemma',)': [0.4695974134334584, 0.35405583...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model_pair  is_normal      stat     p_val  \\\n",
       "6          ((lemma,), (liwc, nrc, adu, lemma))      False -2.216641  0.090951   \n",
       "8  ((lemma,), (nrc, mpqa_subjobg, adu, lemma))       True -2.843135  0.046719   \n",
       "\n",
       "   wilk_stat  wilk_p_val  significant  \\\n",
       "6        0.0    0.043114         True   \n",
       "8        0.0    0.043114         True   \n",
       "\n",
       "                                                data  \n",
       "6  {'('lemma',)': [0.4695974134334584, 0.35405583...  \n",
       "8  {'('lemma',)': [0.4695974134334584, 0.35405583...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_cross_models_sqrt_df[high_cross_models_sqrt_df['significant'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('lemma',)) 2\n",
      "('dummy',)\n",
      "('lemma',)\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('nrc', 'mpqa_arg', 'mpqa_subjobg', 'adu')) 2\n",
      "('dummy',)\n",
      "('nrc', 'mpqa_arg', 'mpqa_subjobg', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('liwc', 'nrc', 'adu')) 2\n",
      "('dummy',)\n",
      "('liwc', 'nrc', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('adu', 'lemma')) 2\n",
      "('dummy',)\n",
      "('adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('nrc', 'mpqa_arg', 'mpqa_subjobg', 'adu')) 2\n",
      "('lemma',)\n",
      "('nrc', 'mpqa_arg', 'mpqa_subjobg', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('liwc', 'nrc', 'adu')) 2\n",
      "('lemma',)\n",
      "('liwc', 'nrc', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('adu', 'lemma')) 2\n",
      "('lemma',)\n",
      "('adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('nrc', 'mpqa_arg', 'mpqa_subjobg', 'adu'), ('liwc', 'nrc', 'adu')) 2\n",
      "('nrc', 'mpqa_arg', 'mpqa_subjobg', 'adu')\n",
      "('liwc', 'nrc', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('nrc', 'mpqa_arg', 'mpqa_subjobg', 'adu'), ('adu', 'lemma')) 2\n",
      "('nrc', 'mpqa_arg', 'mpqa_subjobg', 'adu')\n",
      "('adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'nrc', 'adu'), ('adu', 'lemma')) 2\n",
      "('liwc', 'nrc', 'adu')\n",
      "('adu', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "level= 'low'\n",
    "PATH_RESULT= '../out/style_content_models_results/{}_HAL_experiments_{}_{}_{}_majority.csv'\n",
    "\n",
    "low_cross_models_sqrt_df    = cross.run_model_pairs_significance(PATH_RESULT.format(trait,'sqrt',trait, level), \n",
    "                                                                  df, '{}_{}_majority'.format(trait, level), \n",
    "                                                                  'sqrt'    , 'sqrt_{}_{}'.format(trait, level) \n",
    "                                                                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_pair</th>\n",
       "      <th>is_normal</th>\n",
       "      <th>stat</th>\n",
       "      <th>p_val</th>\n",
       "      <th>wilk_stat</th>\n",
       "      <th>wilk_p_val</th>\n",
       "      <th>significant</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((lemma,), (nrc, mpqa_arg, mpqa_subjobg, adu))</td>\n",
       "      <td>True</td>\n",
       "      <td>2.777149</td>\n",
       "      <td>0.049964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043114</td>\n",
       "      <td>True</td>\n",
       "      <td>{'('lemma',)': [0.42804878048780487, 0.3866857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>((nrc, mpqa_arg, mpqa_subjobg, adu), (adu, lem...</td>\n",
       "      <td>True</td>\n",
       "      <td>-3.428126</td>\n",
       "      <td>0.026581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043114</td>\n",
       "      <td>True</td>\n",
       "      <td>{'('nrc', 'mpqa_arg', 'mpqa_subjobg', 'adu')':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>((liwc, nrc, adu), (adu, lemma))</td>\n",
       "      <td>True</td>\n",
       "      <td>-3.317789</td>\n",
       "      <td>0.029439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043114</td>\n",
       "      <td>True</td>\n",
       "      <td>{'('liwc', 'nrc', 'adu')': [0.4134447927551376...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_pair  is_normal      stat  \\\n",
       "4     ((lemma,), (nrc, mpqa_arg, mpqa_subjobg, adu))       True  2.777149   \n",
       "8  ((nrc, mpqa_arg, mpqa_subjobg, adu), (adu, lem...       True -3.428126   \n",
       "9                   ((liwc, nrc, adu), (adu, lemma))       True -3.317789   \n",
       "\n",
       "      p_val  wilk_stat  wilk_p_val  significant  \\\n",
       "4  0.049964        0.0    0.043114         True   \n",
       "8  0.026581        0.0    0.043114         True   \n",
       "9  0.029439        0.0    0.043114         True   \n",
       "\n",
       "                                                data  \n",
       "4  {'('lemma',)': [0.42804878048780487, 0.3866857...  \n",
       "8  {'('nrc', 'mpqa_arg', 'mpqa_subjobg', 'adu')':...  \n",
       "9  {'('liwc', 'nrc', 'adu')': [0.4134447927551376...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_cross_models_sqrt_df[low_cross_models_sqrt_df['significant'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('lemma',)) 2\n",
      "('dummy',)\n",
      "('lemma',)\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('liwc', 'nrc', 'mpqa_subjobg', 'adu')) 2\n",
      "('dummy',)\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('nrc', 'mpqa_subjobg', 'adu')) 2\n",
      "('dummy',)\n",
      "('nrc', 'mpqa_subjobg', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('liwc', 'adu', 'lemma')) 2\n",
      "('dummy',)\n",
      "('liwc', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('mpqa_arg', 'adu', 'lemma')) 2\n",
      "('dummy',)\n",
      "('mpqa_arg', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('nrc', 'lemma')) 2\n",
      "('dummy',)\n",
      "('nrc', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('liwc', 'nrc', 'mpqa_subjobg', 'adu')) 2\n",
      "('lemma',)\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('nrc', 'mpqa_subjobg', 'adu')) 2\n",
      "('lemma',)\n",
      "('nrc', 'mpqa_subjobg', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('liwc', 'adu', 'lemma')) 2\n",
      "('lemma',)\n",
      "('liwc', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('mpqa_arg', 'adu', 'lemma')) 2\n",
      "('lemma',)\n",
      "('mpqa_arg', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('nrc', 'lemma')) 2\n",
      "('lemma',)\n",
      "('nrc', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'nrc', 'mpqa_subjobg', 'adu'), ('nrc', 'mpqa_subjobg', 'adu')) 2\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu')\n",
      "('nrc', 'mpqa_subjobg', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'nrc', 'mpqa_subjobg', 'adu'), ('liwc', 'adu', 'lemma')) 2\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu')\n",
      "('liwc', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'nrc', 'mpqa_subjobg', 'adu'), ('mpqa_arg', 'adu', 'lemma')) 2\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu')\n",
      "('mpqa_arg', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'nrc', 'mpqa_subjobg', 'adu'), ('nrc', 'lemma')) 2\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu')\n",
      "('nrc', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('nrc', 'mpqa_subjobg', 'adu'), ('liwc', 'adu', 'lemma')) 2\n",
      "('nrc', 'mpqa_subjobg', 'adu')\n",
      "('liwc', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('nrc', 'mpqa_subjobg', 'adu'), ('mpqa_arg', 'adu', 'lemma')) 2\n",
      "('nrc', 'mpqa_subjobg', 'adu')\n",
      "('mpqa_arg', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('nrc', 'mpqa_subjobg', 'adu'), ('nrc', 'lemma')) 2\n",
      "('nrc', 'mpqa_subjobg', 'adu')\n",
      "('nrc', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'adu', 'lemma'), ('mpqa_arg', 'adu', 'lemma')) 2\n",
      "('liwc', 'adu', 'lemma')\n",
      "('mpqa_arg', 'adu', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'adu', 'lemma'), ('nrc', 'lemma')) 2\n",
      "('liwc', 'adu', 'lemma')\n",
      "('nrc', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "openness_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('mpqa_arg', 'adu', 'lemma'), ('nrc', 'lemma')) 2\n",
      "('mpqa_arg', 'adu', 'lemma')\n",
      "('nrc', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "level= 'average'\n",
    "PATH_RESULT= '../out/style_content_models_results/{}_HAL_experiments_{}_{}_{}_majority.csv'\n",
    "\n",
    "average_cross_models_sqrt_df    = cross.run_model_pairs_significance(PATH_RESULT.format(trait,'sqrt',trait, level), \n",
    "                                                                  df, '{}_{}_majority'.format(trait, level), \n",
    "                                                                  'sqrt'    , 'sqrt_{}_{}'.format(trait, level) \n",
    "                                                                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_pair</th>\n",
       "      <th>is_normal</th>\n",
       "      <th>stat</th>\n",
       "      <th>p_val</th>\n",
       "      <th>wilk_stat</th>\n",
       "      <th>wilk_p_val</th>\n",
       "      <th>significant</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_pair, is_normal, stat, p_val, wilk_stat, wilk_p_val, significant, data]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_cross_models_sqrt_df[average_cross_models_sqrt_df['significant'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_RESULT= '../out/style_content_models_results/{}_HAL_experiments_{}_{}_{}_majority.csv'\n",
    "\n",
    "singles_low, low_res = cross.get_top_features_from_path(PATH_RESULT.format(trait,'sqrt',trait, 'low'))\n",
    "singles_avg, avg_res = cross.get_top_features_from_path(PATH_RESULT.format(trait,'sqrt',trait, 'average'))\n",
    "singles_high, high_res = cross.get_top_features_from_path(PATH_RESULT.format(trait,'sqrt',trait, 'high'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>macro</th>\n",
       "      <th>ideology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('liwc', 'adu', 'lemma')</td>\n",
       "      <td>0.4</td>\n",
       "      <td>openness_average_majority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('mpqa_arg', 'adu', 'lemma')</td>\n",
       "      <td>0.4</td>\n",
       "      <td>openness_average_majority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('nrc', 'lemma')</td>\n",
       "      <td>0.4</td>\n",
       "      <td>openness_average_majority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       features  macro                   ideology\n",
       "0      ('liwc', 'adu', 'lemma')    0.4  openness_average_majority\n",
       "2  ('mpqa_arg', 'adu', 'lemma')    0.4  openness_average_majority\n",
       "3              ('nrc', 'lemma')    0.4  openness_average_majority"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_res['content+style'][['features','macro', 'ideology']]\n",
    "#avg_res['style'][['features','macro', 'ideology']]\n",
    "##avg_res['content'][['features','macro', 'ideology']]\n",
    "#singles_avg[(singles_avg['single'] == True )& (singles_avg['type'] == 'style')][['features','macro', 'ideology']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_res['content+style'][['features','macro', 'ideology']]\n",
    "#high_res['style'][['features','macro', 'ideology']]\n",
    "#high_res['content'][['features','macro', 'ideology']]\n",
    "#singles_high[(singles_high['single'] == True )& (singles_high['type'] == 'style')][['features','macro', 'ideology']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
