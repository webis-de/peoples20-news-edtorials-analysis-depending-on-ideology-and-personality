{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elba_ro\\Documents\\projects\\nlpcss2020-editorials-analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\elba_ro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\elba_ro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from langdetect import detect\n",
    "import langdetect\n",
    "import numpy as np\n",
    "import importlib\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "%cd ..\n",
    "import textmining.text_miner \n",
    "import textmining.loader  as loader\n",
    "import textmining.topic_modeler as tm\n",
    "import textmining.significance_testing as significance_testing\n",
    "import textmining.utility as utility\n",
    "import textmining.analysis as analysis\n",
    "import textmining.cluster_analysis as cluster_analysis\n",
    "import textmining.machine_learning as machine_learning\n",
    "import textmining.news_editorials_experiments as experiment\n",
    "import textmining.cross_models_significance as cross\n",
    "\n",
    "importlib.reload(textmining.machine_learning)\n",
    "importlib.reload(textmining.news_editorials_experiments)\n",
    "importlib.reload(textmining.cross_models_significance)\n",
    "importlib.reload(textmining.cluster_analysis)\n",
    "importlib.reload(textmining.text_miner)\n",
    "\n",
    "importlib.reload(textmining.text_miner)\n",
    "importlib.reload(textmining.topic_modeler)\n",
    "importlib.reload(textmining.analysis)\n",
    "importlib.reload(textmining.loader)\n",
    "os.chdir(current_dir)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trait = 'extraversion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"corpus\" is set. It contains the 6000 annotation\n"
     ]
    }
   ],
   "source": [
    "load = loader.loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_df = load.load_personality_traits()\n",
    "personality_df.set_index('id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extraversion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L01</th>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L03</th>\n",
       "      <td>AVERAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L07</th>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C03</th>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C09</th>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C11</th>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L08</th>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L15</th>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L14</th>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C12</th>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C02</th>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C07</th>\n",
       "      <td>AVERAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L12</th>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C15</th>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C14</th>\n",
       "      <td>AVERAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L06</th>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C04</th>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C06</th>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C10</th>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C13</th>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L04</th>\n",
       "      <td>AVERAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L05</th>\n",
       "      <td>AVERAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L09</th>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L11</th>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    extraversion\n",
       "id              \n",
       "L01          LOW\n",
       "L03      AVERAGE\n",
       "L07          LOW\n",
       "C03          LOW\n",
       "C09         HIGH\n",
       "C11          LOW\n",
       "L08         HIGH\n",
       "L15          LOW\n",
       "L14         HIGH\n",
       "C12          LOW\n",
       "C02          LOW\n",
       "C07      AVERAGE\n",
       "L12         HIGH\n",
       "C15          LOW\n",
       "C14      AVERAGE\n",
       "L06         HIGH\n",
       "C04         HIGH\n",
       "C06          LOW\n",
       "C10          LOW\n",
       "C13          LOW\n",
       "L04      AVERAGE\n",
       "L05      AVERAGE\n",
       "L09         HIGH\n",
       "L11          LOW"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traints\n",
    "\n",
    "#personality_df.extraversion.value_counts()\n",
    "personality_df[[trait]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"corpus\" is set with personality: \"a\" , \"b\", ...\n"
     ]
    }
   ],
   "source": [
    "corpus = load.corpus\n",
    "corpus = load.add_personality_label(personality_df[[trait]], trait)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOW        3000\n",
       "HIGH       1750\n",
       "AVERAGE    1250\n",
       "Name: extraversion, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[trait].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(effect_abstracted    1     2     3\n",
       " extraversion                      \n",
       " AVERAGE            103   277   870\n",
       " HIGH               255   352  1143\n",
       " LOW                329  1361  1310,\n",
       " None,\n",
       " None,\n",
       " effect         1    2     3    4    5\n",
       " extraversion                         \n",
       " AVERAGE       48   55   277  479  391\n",
       " HIGH          40  215   352  760  383\n",
       " LOW           55  274  1361  961  349)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(corpus[trait], corpus.effect_abstracted), print(''),print(''), pd.crosstab(corpus[trait], corpus.effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles dataframe for ideology AVERAGE was created\n",
      "The id of the df is the article id without txt\n",
      "total con: 979\n",
      "rounded TRAINGING data:  783\n",
      "rounded Validation data:  0\n",
      "rounded Test data:  196\n",
      "total con: 1000\n",
      "rounded TRAINGING data:  800\n",
      "rounded Validation data:  0\n",
      "rounded Test data:  200\n",
      "\"data_division\" is set as dict with keys  dict_keys(['train', 'test'])\n",
      "\"corpus\" is set with split_label: \"train\" \"test\"\n",
      "\"data_division\" is set as dict with keys  dict_keys(['train', 'test'])\n",
      "length of self.df:  979\n",
      "length of self.data_division_df:  979\n",
      "length of self.df:  979\n",
      "articles dataframe for ideology HIGH was created\n",
      "The id of the df is the article id without txt\n",
      "total con: 979\n",
      "rounded TRAINGING data:  783\n",
      "rounded Validation data:  0\n",
      "rounded Test data:  196\n",
      "total con: 1000\n",
      "rounded TRAINGING data:  800\n",
      "rounded Validation data:  0\n",
      "rounded Test data:  200\n",
      "\"data_division\" is set as dict with keys  dict_keys(['train', 'test'])\n",
      "\"corpus\" is set with split_label: \"train\" \"test\"\n",
      "\"data_division\" is set as dict with keys  dict_keys(['train', 'test'])\n",
      "length of self.df:  979\n",
      "length of self.data_division_df:  979\n",
      "length of self.df:  979\n",
      "articles dataframe for ideology LOW was created\n",
      "The id of the df is the article id without txt\n",
      "total con: 979\n",
      "rounded TRAINGING data:  783\n",
      "rounded Validation data:  0\n",
      "rounded Test data:  196\n",
      "total con: 1000\n",
      "rounded TRAINGING data:  800\n",
      "rounded Validation data:  0\n",
      "rounded Test data:  200\n",
      "\"data_division\" is set as dict with keys  dict_keys(['train', 'test'])\n",
      "\"corpus\" is set with split_label: \"train\" \"test\"\n",
      "\"data_division\" is set as dict with keys  dict_keys(['train', 'test'])\n",
      "length of self.df:  979\n",
      "length of self.data_division_df:  979\n",
      "length of self.df:  979\n"
     ]
    }
   ],
   "source": [
    "extraversion_maj_df = load.get_article_dfs_per_ideology(ideology = trait, include_content = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_df = extraversion_maj_df['HIGH']\n",
    "average_df = extraversion_maj_df['AVERAGE']\n",
    "low_df = extraversion_maj_df['LOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_all_0(df):\n",
    "    return  df[(df['challenging']== 0) & (df['no_effect']== 0) & (df['reinforcing']== 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reinforcing    611\n",
      "challenging    224\n",
      "no_effect      144\n",
      "Name: majority, dtype: int64\n",
      "\n",
      "reinforcing    731\n",
      "no_effect      147\n",
      "challenging    101\n",
      "Name: majority, dtype: int64\n",
      "\n",
      "reinforcing    490\n",
      "no_effect      361\n",
      "challenging    128\n",
      "Name: majority, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(low_df.majority.value_counts())\n",
    "\n",
    "print()\n",
    "\n",
    "print(average_df.majority.value_counts())\n",
    "print()\n",
    "\n",
    "print(high_df.majority.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train    783\n",
      "test     196\n",
      "Name: split_label, dtype: int64\n",
      "\n",
      "train    783\n",
      "test     196\n",
      "Name: split_label, dtype: int64\n",
      "\n",
      "train    783\n",
      "test     196\n",
      "Name: split_label, dtype: int64\n",
      "\n",
      "\n",
      "split_label  test  train\n",
      "majority                \n",
      "challenging    22    106\n",
      "no_effect      80    281\n",
      "reinforcing    94    396\n",
      "\n",
      "split_label  test  train\n",
      "majority                \n",
      "challenging    18     83\n",
      "no_effect      21    126\n",
      "reinforcing   157    574\n",
      "\n",
      "split_label  test  train\n",
      "majority                \n",
      "challenging    53    171\n",
      "no_effect      25    119\n",
      "reinforcing   118    493\n"
     ]
    }
   ],
   "source": [
    "print(high_df.split_label.value_counts())\n",
    "print()\n",
    "print(average_df.split_label.value_counts())\n",
    "print()\n",
    "print(low_df.split_label.value_counts())\n",
    "print()\n",
    "print()\n",
    "print(pd.crosstab(low_df.majority, low_df.split_label))\n",
    "print()\n",
    "print(pd.crosstab(average_df.majority, average_df.split_label))\n",
    "print()\n",
    "print(pd.crosstab(high_df.majority, high_df.split_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_df.rename(columns = {'majority': trait+'_high_majority'}, inplace = True)\n",
    "average_df.rename(columns = {'majority': trait+'_average_majority'}, inplace = True)\n",
    "low_df.rename(columns = {'majority': trait+'_low_majority'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../data/articles_with_adu_liwc_lexicons_content.json', orient='records')\n",
    "data.set_index('idx', inplace=True)\n",
    "print(len(data))\n",
    "data = data.merge(high_df[[<]], how=\"inner\",left_index=True, right_index=True )\n",
    "data = data.merge(average_df[[trait+'_average_majority']], how=\"inner\",left_index=True, right_index=True )\n",
    "data = data.merge(low_df[[trait+'_low_majority']], how=\"inner\",left_index=True, right_index=True )\n",
    "\n",
    "data.drop(['liberal_majority', 'conservative_majority'], axis=1, inplace=True)\n",
    "data.to_csv('../data/'+trait+'_HAL_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, test_df = analysis.get_train_test(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/'+trait+'_HAL_all_features.csv', index_col='idx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_sqrt = experiment.run_experiments(df, ideologies=[#trait+'_high_majority', \n",
    "                                                              trait+'_average_majority',\n",
    "                                                             #trait+'_low_majority',\n",
    "],\n",
    "                                              filename=\"../out/style_content_models_results/\"+trait+\"_HAL_experiments_sqrt\",\n",
    "                                              remove_outliers=True,\n",
    "                                              normalize=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.train_baseline(df, trait+'_high_majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.train_baseline(df, trait+'_average_majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.train_baseline(df, trait+'_low_majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_minmax['extraversion_low_majority'].macro.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('lemma',)) 2\n",
      "('dummy',)\n",
      "('lemma',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('nrc', 'mpqa_arg')) 2\n",
      "('dummy',)\n",
      "('nrc', 'mpqa_arg')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('liwc', 'nrc', 'mpqa_subjobg', 'adu')) 2\n",
      "('dummy',)\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('nrc', 'mpqa_subjobg', 'lemma')) 2\n",
      "('dummy',)\n",
      "('nrc', 'mpqa_subjobg', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('nrc', 'mpqa_arg')) 2\n",
      "('lemma',)\n",
      "('nrc', 'mpqa_arg')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('liwc', 'nrc', 'mpqa_subjobg', 'adu')) 2\n",
      "('lemma',)\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('nrc', 'mpqa_subjobg', 'lemma')) 2\n",
      "('lemma',)\n",
      "('nrc', 'mpqa_subjobg', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('nrc', 'mpqa_arg'), ('liwc', 'nrc', 'mpqa_subjobg', 'adu')) 2\n",
      "('nrc', 'mpqa_arg')\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('nrc', 'mpqa_arg'), ('nrc', 'mpqa_subjobg', 'lemma')) 2\n",
      "('nrc', 'mpqa_arg')\n",
      "('nrc', 'mpqa_subjobg', 'lemma')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_high_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'nrc', 'mpqa_subjobg', 'adu'), ('nrc', 'mpqa_subjobg', 'lemma')) 2\n",
      "('liwc', 'nrc', 'mpqa_subjobg', 'adu')\n",
      "('nrc', 'mpqa_subjobg', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "level= 'high'\n",
    "PATH_RESULT= '../out/style_content_models_results/extraversion_HAL_experiments_{}_extraversion_{}_majority.csv'\n",
    "\n",
    "high_cross_models_sqrt_df    = cross.run_model_pairs_significance(PATH_RESULT.format('sqrt', level), \n",
    "                                                                  df, '{}_{}_majority'.format(trait, level), \n",
    "                                                                  'sqrt'    , 'sqrt_{}_{}'.format(trait, level) \n",
    "                                                                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_pair</th>\n",
       "      <th>is_normal</th>\n",
       "      <th>stat</th>\n",
       "      <th>p_val</th>\n",
       "      <th>wilk_stat</th>\n",
       "      <th>wilk_p_val</th>\n",
       "      <th>significant</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((dummy,), (lemma,))</td>\n",
       "      <td>True</td>\n",
       "      <td>3.448616</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043114</td>\n",
       "      <td>True</td>\n",
       "      <td>{'('dummy',)': [0.37, 0.51, 0.32, 0.35, 0.44],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((dummy,), (nrc, mpqa_arg))</td>\n",
       "      <td>True</td>\n",
       "      <td>2.815223</td>\n",
       "      <td>0.048061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043114</td>\n",
       "      <td>True</td>\n",
       "      <td>{'('dummy',)': [0.37, 0.51, 0.32, 0.35, 0.44],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((dummy,), (liwc, nrc, mpqa_subjobg, adu))</td>\n",
       "      <td>True</td>\n",
       "      <td>0.739112</td>\n",
       "      <td>0.500863</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.500184</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('dummy',)': [0.37, 0.51, 0.32, 0.35, 0.44],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((dummy,), (nrc, mpqa_subjobg, lemma))</td>\n",
       "      <td>True</td>\n",
       "      <td>1.282825</td>\n",
       "      <td>0.268842</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.345231</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('dummy',)': [0.37, 0.51, 0.32, 0.35, 0.44],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((lemma,), (nrc, mpqa_arg))</td>\n",
       "      <td>True</td>\n",
       "      <td>0.223850</td>\n",
       "      <td>0.833842</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.892738</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('lemma',)': [0.33814820164668496, 0.4281865...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>((lemma,), (liwc, nrc, mpqa_subjobg, adu))</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.073897</td>\n",
       "      <td>0.944640</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.685830</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('lemma',)': [0.33814820164668496, 0.4281865...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>((lemma,), (nrc, mpqa_subjobg, lemma))</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.231288</td>\n",
       "      <td>0.285659</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.224916</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('lemma',)': [0.33814820164668496, 0.4281865...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>((nrc, mpqa_arg), (liwc, nrc, mpqa_subjobg, adu))</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.152013</td>\n",
       "      <td>0.886536</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.892738</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('nrc', 'mpqa_arg')': [0.3483709273182958, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>((nrc, mpqa_arg), (nrc, mpqa_subjobg, lemma))</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.696917</td>\n",
       "      <td>0.524234</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.685830</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('nrc', 'mpqa_arg')': [0.3483709273182958, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>((liwc, nrc, mpqa_subjobg, adu), (nrc, mpqa_su...</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.267594</td>\n",
       "      <td>0.802244</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.685830</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('liwc', 'nrc', 'mpqa_subjobg', 'adu')': [0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_pair  is_normal      stat  \\\n",
       "0                               ((dummy,), (lemma,))       True  3.448616   \n",
       "1                        ((dummy,), (nrc, mpqa_arg))       True  2.815223   \n",
       "2         ((dummy,), (liwc, nrc, mpqa_subjobg, adu))       True  0.739112   \n",
       "3             ((dummy,), (nrc, mpqa_subjobg, lemma))       True  1.282825   \n",
       "4                        ((lemma,), (nrc, mpqa_arg))       True  0.223850   \n",
       "5         ((lemma,), (liwc, nrc, mpqa_subjobg, adu))       True -0.073897   \n",
       "6             ((lemma,), (nrc, mpqa_subjobg, lemma))       True -1.231288   \n",
       "7  ((nrc, mpqa_arg), (liwc, nrc, mpqa_subjobg, adu))       True -0.152013   \n",
       "8      ((nrc, mpqa_arg), (nrc, mpqa_subjobg, lemma))       True -0.696917   \n",
       "9  ((liwc, nrc, mpqa_subjobg, adu), (nrc, mpqa_su...       True -0.267594   \n",
       "\n",
       "      p_val  wilk_stat  wilk_p_val  significant  \\\n",
       "0  0.026087        0.0    0.043114         True   \n",
       "1  0.048061        0.0    0.043114         True   \n",
       "2  0.500863        5.0    0.500184        False   \n",
       "3  0.268842        4.0    0.345231        False   \n",
       "4  0.833842        7.0    0.892738        False   \n",
       "5  0.944640        6.0    0.685830        False   \n",
       "6  0.285659        3.0    0.224916        False   \n",
       "7  0.886536        7.0    0.892738        False   \n",
       "8  0.524234        6.0    0.685830        False   \n",
       "9  0.802244        6.0    0.685830        False   \n",
       "\n",
       "                                                data  \n",
       "0  {'('dummy',)': [0.37, 0.51, 0.32, 0.35, 0.44],...  \n",
       "1  {'('dummy',)': [0.37, 0.51, 0.32, 0.35, 0.44],...  \n",
       "2  {'('dummy',)': [0.37, 0.51, 0.32, 0.35, 0.44],...  \n",
       "3  {'('dummy',)': [0.37, 0.51, 0.32, 0.35, 0.44],...  \n",
       "4  {'('lemma',)': [0.33814820164668496, 0.4281865...  \n",
       "5  {'('lemma',)': [0.33814820164668496, 0.4281865...  \n",
       "6  {'('lemma',)': [0.33814820164668496, 0.4281865...  \n",
       "7  {'('nrc', 'mpqa_arg')': [0.3483709273182958, 0...  \n",
       "8  {'('nrc', 'mpqa_arg')': [0.3483709273182958, 0...  \n",
       "9  {'('liwc', 'nrc', 'mpqa_subjobg', 'adu')': [0....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_cross_models_sqrt_df\n",
    "#(nrc, mpqa_arg)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model pickle was not created. Creating it now\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "performing gridsearch\n",
      "saving file:  ../out/models/extraversion_low_majority/sqrt_lemma.pkl\n",
      "training and saving\n",
      "running  svm  with params  {'C': 1, 'class_weight': 'balanced'}\n",
      "model pickle was not created. Creating it now\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "performing gridsearch\n",
      "saving file:  ../out/models/extraversion_low_majority/sqrt_liwc-nrc-mpqa_arg-adu.pkl\n",
      "training and saving\n",
      "running  svm  with params  {'C': 100, 'class_weight': 'balanced'}\n",
      "model pickle was not created. Creating it now\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "performing gridsearch\n",
      "saving file:  ../out/models/extraversion_low_majority/sqrt_mpqa_subjobg-adu-lemma.pkl\n",
      "training and saving\n",
      "running  svm  with params  {'C': 10, 'class_weight': 'balanced'}\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('lemma',)) 2\n",
      "('dummy',)\n",
      "('lemma',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('liwc', 'nrc', 'mpqa_arg', 'adu')) 2\n",
      "('dummy',)\n",
      "('liwc', 'nrc', 'mpqa_arg', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('dummy',)\n",
      "('mpqa_subjobg', 'adu', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('liwc', 'nrc', 'mpqa_arg', 'adu')) 2\n",
      "('lemma',)\n",
      "('liwc', 'nrc', 'mpqa_arg', 'adu')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('lemma',)\n",
      "('mpqa_subjobg', 'adu', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_low_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'nrc', 'mpqa_arg', 'adu'), ('mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('liwc', 'nrc', 'mpqa_arg', 'adu')\n",
      "('mpqa_subjobg', 'adu', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "level= 'low'\n",
    "PATH_RESULT= '../out/style_content_models_results/extraversion_HAL_experiments_{}_extraversion_{}_majority.csv'\n",
    "\n",
    "low_cross_models_sqrt_df    = cross.run_model_pairs_significance(PATH_RESULT.format('sqrt', level), \n",
    "                                                                  df, '{}_{}_majority'.format(trait, level), \n",
    "                                                                  'sqrt'    , 'sqrt_{}_{}'.format(trait, level) \n",
    "                                                                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_pair</th>\n",
       "      <th>is_normal</th>\n",
       "      <th>stat</th>\n",
       "      <th>p_val</th>\n",
       "      <th>wilk_stat</th>\n",
       "      <th>wilk_p_val</th>\n",
       "      <th>significant</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((dummy,), (lemma,))</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.786716</td>\n",
       "      <td>0.475441</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.345231</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('dummy',)': [0.27, 0.47, 0.3, 0.27, 0.27], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((dummy,), (liwc, nrc, mpqa_arg, adu))</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.039859</td>\n",
       "      <td>0.357127</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.345231</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('dummy',)': [0.27, 0.47, 0.3, 0.27, 0.27], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((dummy,), (mpqa_subjobg, adu, lemma))</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.471988</td>\n",
       "      <td>0.215001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.224916</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('dummy',)': [0.27, 0.47, 0.3, 0.27, 0.27], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((lemma,), (liwc, nrc, mpqa_arg, adu))</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.239867</td>\n",
       "      <td>0.282791</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.224916</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('lemma',)': [0.40489685752843646, 0.3746498...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((lemma,), (mpqa_subjobg, adu, lemma))</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.100856</td>\n",
       "      <td>0.103553</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.138011</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('lemma',)': [0.40489685752843646, 0.3746498...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>((liwc, nrc, mpqa_arg, adu), (mpqa_subjobg, ad...</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.354923</td>\n",
       "      <td>0.740570</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.685830</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('liwc', 'nrc', 'mpqa_arg', 'adu')': [0.5501...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_pair  is_normal      stat  \\\n",
       "0                               ((dummy,), (lemma,))       True -0.786716   \n",
       "1             ((dummy,), (liwc, nrc, mpqa_arg, adu))       True -1.039859   \n",
       "2             ((dummy,), (mpqa_subjobg, adu, lemma))       True -1.471988   \n",
       "3             ((lemma,), (liwc, nrc, mpqa_arg, adu))       True -1.239867   \n",
       "4             ((lemma,), (mpqa_subjobg, adu, lemma))       True -2.100856   \n",
       "5  ((liwc, nrc, mpqa_arg, adu), (mpqa_subjobg, ad...       True -0.354923   \n",
       "\n",
       "      p_val  wilk_stat  wilk_p_val  significant  \\\n",
       "0  0.475441        4.0    0.345231        False   \n",
       "1  0.357127        4.0    0.345231        False   \n",
       "2  0.215001        3.0    0.224916        False   \n",
       "3  0.282791        3.0    0.224916        False   \n",
       "4  0.103553        2.0    0.138011        False   \n",
       "5  0.740570        6.0    0.685830        False   \n",
       "\n",
       "                                                data  \n",
       "0  {'('dummy',)': [0.27, 0.47, 0.3, 0.27, 0.27], ...  \n",
       "1  {'('dummy',)': [0.27, 0.47, 0.3, 0.27, 0.27], ...  \n",
       "2  {'('dummy',)': [0.27, 0.47, 0.3, 0.27, 0.27], ...  \n",
       "3  {'('lemma',)': [0.40489685752843646, 0.3746498...  \n",
       "4  {'('lemma',)': [0.40489685752843646, 0.3746498...  \n",
       "5  {'('liwc', 'nrc', 'mpqa_arg', 'adu')': [0.5501...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_cross_models_sqrt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model pickle was not created. Creating it now\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "performing gridsearch\n",
      "saving file:  ../out/models/extraversion_average_majority/sqrt_lemma.pkl\n",
      "training and saving\n",
      "running  svm  with params  {'C': 100, 'class_weight': 'balanced'}\n",
      "model pickle was not created. Creating it now\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "performing gridsearch\n",
      "saving file:  ../out/models/extraversion_average_majority/sqrt_liwc-mpqa_subjobg-adu.pkl\n",
      "training and saving\n",
      "running  svm  with params  {'C': 100, 'class_weight': 'balanced'}\n",
      "model pickle was not created. Creating it now\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "performing gridsearch\n",
      "saving file:  ../out/models/extraversion_average_majority/sqrt_liwc-lemma.pkl\n",
      "training and saving\n",
      "running  svm  with params  {'C': 100, 'class_weight': 'balanced'}\n",
      "model pickle was not created. Creating it now\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "performing gridsearch\n",
      "saving file:  ../out/models/extraversion_average_majority/sqrt_liwc-mpqa_subjobg-adu-lemma.pkl\n",
      "training and saving\n",
      "running  svm  with params  {'C': 100, 'class_weight': 'balanced'}\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('lemma',)) 2\n",
      "('dummy',)\n",
      "('lemma',)\n",
      "preprocessing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('liwc', 'mpqa_subjobg', 'adu')) 2\n",
      "('dummy',)\n",
      "('liwc', 'mpqa_subjobg', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('liwc', 'lemma')) 2\n",
      "('dummy',)\n",
      "('liwc', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('dummy',), ('liwc', 'mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('dummy',)\n",
      "('liwc', 'mpqa_subjobg', 'adu', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('liwc', 'mpqa_subjobg', 'adu')) 2\n",
      "('lemma',)\n",
      "('liwc', 'mpqa_subjobg', 'adu')\n",
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('liwc', 'lemma')) 2\n",
      "('lemma',)\n",
      "('liwc', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('lemma',), ('liwc', 'mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('lemma',)\n",
      "('liwc', 'mpqa_subjobg', 'adu', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'mpqa_subjobg', 'adu'), ('liwc', 'lemma')) 2\n",
      "('liwc', 'mpqa_subjobg', 'adu')\n",
      "('liwc', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'mpqa_subjobg', 'adu'), ('liwc', 'mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('liwc', 'mpqa_subjobg', 'adu')\n",
      "('liwc', 'mpqa_subjobg', 'adu', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data...\n",
      "removing outliers by clipping values...\n",
      "getting only numeric features from the training set...\n",
      "There are 428  numeric features out of 435\n",
      "getting X y data...\n",
      "Normalizing by using sqrt scaler...\n",
      "normalized\n",
      "end of get_x_y.\n",
      "END of preprocessing\n",
      "extraversion_average_majority\n",
      "+++++++++++++++++++++++++++++++++++++++++++++\n",
      "(('liwc', 'lemma'), ('liwc', 'mpqa_subjobg', 'adu', 'lemma')) 2\n",
      "('liwc', 'lemma')\n",
      "('liwc', 'mpqa_subjobg', 'adu', 'lemma')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "level= 'average'\n",
    "PATH_RESULT= '../out/style_content_models_results/extraversion_HAL_experiments_{}_extraversion_{}_majority.csv'\n",
    "\n",
    "average_cross_models_sqrt_df    = cross.run_model_pairs_significance(PATH_RESULT.format('sqrt', level), \n",
    "                                                                  df, '{}_{}_majority'.format(trait, level), \n",
    "                                                                  'sqrt'    , 'sqrt_{}_{}'.format(trait, level) \n",
    "                                                                 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_pair</th>\n",
       "      <th>is_normal</th>\n",
       "      <th>stat</th>\n",
       "      <th>p_val</th>\n",
       "      <th>wilk_stat</th>\n",
       "      <th>wilk_p_val</th>\n",
       "      <th>significant</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((dummy,), (lemma,))</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.881833</td>\n",
       "      <td>0.044930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.079616</td>\n",
       "      <td>True</td>\n",
       "      <td>{'('dummy',)': [0.28, 0.28, 0.24, 0.2, 0.32], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((dummy,), (liwc, mpqa_subjobg, adu))</td>\n",
       "      <td>True</td>\n",
       "      <td>-3.702894</td>\n",
       "      <td>0.020783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043114</td>\n",
       "      <td>True</td>\n",
       "      <td>{'('dummy',)': [0.28, 0.28, 0.24, 0.2, 0.32], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((dummy,), (liwc, lemma))</td>\n",
       "      <td>True</td>\n",
       "      <td>-4.648383</td>\n",
       "      <td>0.009673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043114</td>\n",
       "      <td>True</td>\n",
       "      <td>{'('dummy',)': [0.28, 0.28, 0.24, 0.2, 0.32], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((dummy,), (liwc, mpqa_subjobg, adu, lemma))</td>\n",
       "      <td>True</td>\n",
       "      <td>-4.133174</td>\n",
       "      <td>0.014457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043114</td>\n",
       "      <td>True</td>\n",
       "      <td>{'('dummy',)': [0.28, 0.28, 0.24, 0.2, 0.32], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((lemma,), (liwc, mpqa_subjobg, adu))</td>\n",
       "      <td>False</td>\n",
       "      <td>1.053387</td>\n",
       "      <td>0.351588</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.500184</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('lemma',)': [0.4293771043771044, 0.23809523...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>((lemma,), (liwc, lemma))</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.037695</td>\n",
       "      <td>0.358021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.345231</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('lemma',)': [0.4293771043771044, 0.23809523...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>((lemma,), (liwc, mpqa_subjobg, adu, lemma))</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.213743</td>\n",
       "      <td>0.291609</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.224916</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('lemma',)': [0.4293771043771044, 0.23809523...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>((liwc, mpqa_subjobg, adu), (liwc, lemma))</td>\n",
       "      <td>True</td>\n",
       "      <td>-2.087354</td>\n",
       "      <td>0.105145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.079616</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('liwc', 'mpqa_subjobg', 'adu')': [0.3060528...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>((liwc, mpqa_subjobg, adu), (liwc, mpqa_subjob...</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.951066</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.138011</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('liwc', 'mpqa_subjobg', 'adu')': [0.3060528...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>((liwc, lemma), (liwc, mpqa_subjobg, adu, lemma))</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.536649</td>\n",
       "      <td>0.619967</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.685830</td>\n",
       "      <td>False</td>\n",
       "      <td>{'('liwc', 'lemma')': [0.3755892255892257, 0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_pair  is_normal      stat  \\\n",
       "0                               ((dummy,), (lemma,))       True -2.881833   \n",
       "1              ((dummy,), (liwc, mpqa_subjobg, adu))       True -3.702894   \n",
       "2                          ((dummy,), (liwc, lemma))       True -4.648383   \n",
       "3       ((dummy,), (liwc, mpqa_subjobg, adu, lemma))       True -4.133174   \n",
       "4              ((lemma,), (liwc, mpqa_subjobg, adu))      False  1.053387   \n",
       "5                          ((lemma,), (liwc, lemma))       True -1.037695   \n",
       "6       ((lemma,), (liwc, mpqa_subjobg, adu, lemma))       True -1.213743   \n",
       "7         ((liwc, mpqa_subjobg, adu), (liwc, lemma))       True -2.087354   \n",
       "8  ((liwc, mpqa_subjobg, adu), (liwc, mpqa_subjob...       True -1.951066   \n",
       "9  ((liwc, lemma), (liwc, mpqa_subjobg, adu, lemma))       True -0.536649   \n",
       "\n",
       "      p_val  wilk_stat  wilk_p_val  significant  \\\n",
       "0  0.044930        1.0    0.079616         True   \n",
       "1  0.020783        0.0    0.043114         True   \n",
       "2  0.009673        0.0    0.043114         True   \n",
       "3  0.014457        0.0    0.043114         True   \n",
       "4  0.351588        5.0    0.500184        False   \n",
       "5  0.358021        4.0    0.345231        False   \n",
       "6  0.291609        3.0    0.224916        False   \n",
       "7  0.105145        1.0    0.079616        False   \n",
       "8  0.122807        2.0    0.138011        False   \n",
       "9  0.619967        6.0    0.685830        False   \n",
       "\n",
       "                                                data  \n",
       "0  {'('dummy',)': [0.28, 0.28, 0.24, 0.2, 0.32], ...  \n",
       "1  {'('dummy',)': [0.28, 0.28, 0.24, 0.2, 0.32], ...  \n",
       "2  {'('dummy',)': [0.28, 0.28, 0.24, 0.2, 0.32], ...  \n",
       "3  {'('dummy',)': [0.28, 0.28, 0.24, 0.2, 0.32], ...  \n",
       "4  {'('lemma',)': [0.4293771043771044, 0.23809523...  \n",
       "5  {'('lemma',)': [0.4293771043771044, 0.23809523...  \n",
       "6  {'('lemma',)': [0.4293771043771044, 0.23809523...  \n",
       "7  {'('liwc', 'mpqa_subjobg', 'adu')': [0.3060528...  \n",
       "8  {'('liwc', 'mpqa_subjobg', 'adu')': [0.3060528...  \n",
       "9  {'('liwc', 'lemma')': [0.3755892255892257, 0.3...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_cross_models_sqrt_df\n",
    "\n",
    "#(liwc, subjectivity, evidence)) \t\n",
    "#  (liwc, lemma)\n",
    "#(liwc, subjectivity, evidence, lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_RESULT= '../out/style_content_models_results/{}_HAL_experiments_{}_{}_{}_majority.csv'\n",
    "\n",
    "singles_low, low_res = cross.get_top_features_from_path(PATH_RESULT.format(trait,'sqrt',trait, 'low'))\n",
    "singles_avg, avg_res = cross.get_top_features_from_path(PATH_RESULT.format(trait,'sqrt',trait, 'average'))\n",
    "singles_high, high_res = cross.get_top_features_from_path(PATH_RESULT.format(trait,'sqrt',trait, 'high'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res['content+style'][['features','macro', 'ideology']]\n",
    "low_res['style'][['features','macro', 'ideology']]\n",
    "low_res['content'][['features','macro', 'ideology']]\n",
    "singles_low[(singles_low['single'] == True )& (singles_low['type'] == 'style')][['features','macro', 'ideology']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_res['content+style'][['features','macro', 'ideology']]\n",
    "avg_res['style'][['features','macro', 'ideology']]\n",
    "avg_res['content'][['features','macro', 'ideology']]\n",
    "singles_avg[(singles_avg['single'] == True )& (singles_avg['type'] == 'style')][['features','macro', 'ideology']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_res['content+style'][['features','macro', 'ideology']]\n",
    "#high_res['style'][['features','macro', 'ideology']]\n",
    "#high_res['content'][['features','macro', 'ideology']]\n",
    "#singles_high[(singles_high['single'] == True )& (singles_high['type'] == 'style')][['features','macro', 'ideology']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
